{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMWRlLuvhO8DiLgl81del0H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vC6XaRp7Z0XP","executionInfo":{"status":"ok","timestamp":1715360595362,"user_tz":-120,"elapsed":11112,"user":{"displayName":"Agustin Martin Picard","userId":"03361323072356609938"}},"outputId":"2548a1a1-bbb9-46bb-fd47-158d61e92654"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-1-5256c16624e0>:8: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n","  plt.style.use('seaborn')\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["import os\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import *\n","\n","from matplotlib import pyplot as plt\n","plt.style.use('seaborn')\n","%config InlineBackend.figure_format = 'retina'\n","\n","def set_size(w,h):\n","  \"\"\"Set matplot figure size\"\"\"\n","  plt.rcParams[\"figure.figsize\"] = [w,h]\n","\n","def show(img):\n","  img = np.array(img)\n","  img -= img.min()\n","  img /= img.max()\n","  plt.imshow(img)\n","  plt.axis('off')\n","\n","import seaborn as sns\n","sns.set(font_scale=0.9)\n","\n","def r(n):\n","  return round(float(n), 3)\n","\n","def clip_percentile(img, p=0.1):\n","  return np.clip(img, np.percentile(img, p), np.percentile(img, 100-p))\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","!cp -r \"/content/drive/MyDrive/Revisiting Feature Viz/data/reference_spectrum\" ./"]},{"cell_type":"code","source":["!pip install kecam"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMpisOmUa5Ha","executionInfo":{"status":"ok","timestamp":1715360601435,"user_tz":-120,"elapsed":6078,"user":{"displayName":"Agustin Martin Picard","userId":"03361323072356609938"}},"outputId":"bc2b3fe1-9ccc-4006-e183-acfab6b9df57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kecam in /usr/local/lib/python3.10/dist-packages (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from kecam) (3.9.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from kecam) (9.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kecam) (4.66.4)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from kecam) (6.2.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from kecam) (2023.12.25)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->kecam) (0.2.13)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py->kecam) (1.25.2)\n"]}]},{"cell_type":"code","source":["from scipy.ndimage import gaussian_filter as gaussian\n","import PIL\n","\n","def plot(t):\n","  \"\"\" Remove outlier and plot image \"\"\"\n","  t = clip_percentile(t, 0.1)\n","  t -= t.mean(); t /= t.std()\n","  t -= t.min(); t /= t.max()\n","  plt.imshow(t)\n","  plt.axis('off')\n","\n","def plot_alpha(t, tr):\n","  \"\"\" Remove outlier and plot image (take care of merging the alpha) \"\"\"\n","  t = clip_percentile(img, 0.1)\n","  t -= t.mean(); t /= t.std()\n","  t -= t.min(); t /= t.max()\n","\n","  tr = np.mean(tr, -1, keepdims=True)\n","  tr = gaussian(tr, sigma=50)\n","  tr = np.clip(tr, 0, np.percentile(tr, 75))\n","  tr /= tr.max()\n","\n","  viz = np.concatenate([t, tr], -1)\n","  plt.imshow(viz)\n","  plt.axis('off')\n","\n","  return viz"],"metadata":{"id":"ZAtkzoYZZ9nj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imagenet_color_correlation = tf.cast(\n","      [[0.56282854, 0.58447580, 0.58447580],\n","       [0.19482528, 0.00000000,-0.19482528],\n","       [0.04329450,-0.10823626, 0.06494176]], tf.float32\n",")\n","\n","def recorrelate_colors(images):\n","    images_flat = tf.reshape(images, [-1, 3])\n","    images_flat = tf.matmul(images_flat, imagenet_color_correlation)\n","    return tf.reshape(images_flat, tf.shape(images))"],"metadata":{"id":"cirXSBPpZ_S8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from kecam import beit, flexivit"],"metadata":{"id":"T_Dm0VFka0Ja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model_vit = beit.BeitBasePatch16(input_shape=(384, 384, 3), pretrained=\"imagenet21k-ft1k\", classifier_activation=\"linear\")\n","model_vit = flexivit.FlexiViTSmall(input_shape=(240, 240, 3), classifier_activation=\"linear\")\n","# flex = tf.keras.applications.ResNet50V2(classifier_activation=None)\n","model = tf.keras.Model(model_vit.input, model_vit.layers[-2].output)\n","#model = beit.BeitBasePatch16(input_shape=(384, 384, 3), pretrained=\"imagenet21k-ft1k\", classifier_activation=\"linear\")\n","# MODEL_INPUT_SIZE = (224, 224)\n","MODEL_INPUT_SIZE = (240, 240)\n","# MODEL_INPUT_SIZE = (384, 384)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SwoC4JqaBhq","executionInfo":{"status":"ok","timestamp":1715360986862,"user_tz":-120,"elapsed":4315,"user":{"displayName":"Agustin Martin Picard","userId":"03361323072356609938"}},"outputId":"c4f56e60-4d82-4826-c4c0-4006243de1d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">>>> Load pretrained from: /root/.keras/models/flexivit_small_240_imagenet.h5\n"]}]},{"cell_type":"code","source":["model_vit.name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"WhioUjC4eKsI","executionInfo":{"status":"ok","timestamp":1715360986863,"user_tz":-120,"elapsed":10,"user":{"displayName":"Agustin Martin Picard","userId":"03361323072356609938"}},"outputId":"01be3cdf-a8e7-4321-8b03-f0322a3dc4d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'flexivit_small'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["@tf.function\n","def cosine_similarity(tensor_a: tf.Tensor, tensor_b: tf.Tensor) -> tf.Tensor:\n","    tensor_a = tf.nn.l2_normalize(tensor_a, axis=-1)\n","    tensor_b = tf.nn.l2_normalize(tensor_b, axis=-1)\n","    return tf.reduce_sum(tensor_a * tensor_b, axis=-1)\n","\n","@tf.function\n","def dot_cossim(tensor_a: tf.Tensor, tensor_b: tf.Tensor, cossim_pow: float = 2.0) -> tf.Tensor:\n","    cosim = tf.maximum(cosine_similarity(tensor_a, tensor_b), 1e-1) ** cossim_pow\n","    dot = tf.reduce_sum(tensor_a * tensor_b)\n","    return dot * cosim"],"metadata":{"id":"z-kwHlSIaDFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","SIZE = 2048\n","\n","def init_buffer(size = 2048, std=0.5):\n","  spectrum_shape = (size, size//2+1)\n","\n","  # init randomly the phase and load the constrained spectrum (average spectrum)\n","  phase = np.random.normal(size=(3, size, size//2+1), scale=std).astype(np.float32)\n","  magnitude = np.load(\"/content/reference_spectrum/decorrelated_1024.npy\")\n","\n","  magnitude = tf.image.resize(np.moveaxis(magnitude, 0, -1), spectrum_shape).numpy()\n","  magnitude = np.moveaxis(magnitude, -1, 0)\n","\n","  return tf.cast(magnitude, tf.float32), tf.cast(phase, tf.float32)\n","\n","# IMPORTANT :\n","# change this value to adapt for model input range\n","# multiplier = 1 means [-1, 1],\n","# multiplier = 2 means [-2, 2]...\n","MULTIPLIER = 1.0\n","\n","@tf.function\n","def fft_to_rgb(magnitude_template, magnitude_alpha, phase):\n","\n","  magnitude = magnitude_template * magnitude_alpha\n","\n","  phase = phase - tf.reduce_mean(phase)\n","  phase /= tf.math.reduce_std(phase)\n","\n","  buffer = tf.complex(tf.cos(phase) * magnitude, tf.sin(phase) * magnitude)\n","  img = tf.signal.irfft2d(buffer)\n","  img = tf.transpose(img, [1,2,0])\n","\n","  img -= tf.reduce_mean(img)\n","  img = img / (tf.math.reduce_std(img) * 2.0 + 1e-3)\n","\n","  img = recorrelate_colors(img)\n","  img = tf.nn.sigmoid(img) * 2.0 - 1.0\n","\n","  return img\n","\n","@tf.function\n","def up_neurons(model, magnitude_template, magnitude_alpha, phase,\n","               box_average_size, box_size_std,\n","               noise_std, nb_crops):\n","\n","  with tf.GradientTape() as tape:\n","    tape.watch(phase)\n","    tape.watch(magnitude_alpha)\n","\n","    image = fft_to_rgb(magnitude_template, magnitude_alpha, phase)\n","    x = image\n","\n","    # sample random crops in the buffer\n","    x0 = 0.5 + tf.random.normal((nb_crops,), stddev=0.15)\n","    y0 = 0.5 + tf.random.normal((nb_crops,), stddev=0.15)\n","    delta_x = tf.random.uniform((nb_crops,), minval=0.05, maxval=0.7)\n","    #delta_x = tf.clip_by_value(delta_x, 0.03, 1.0)\n","    delta_y = delta_x # square boxes\n","\n","    box_indices = tf.zeros(shape=(nb_crops,), dtype=tf.int32)\n","    boxes = tf.stack([x0 - delta_x * 0.5,\n","                      y0 - delta_y * 0.5,\n","                      x0 + delta_x * 0.5,\n","                      y0 + delta_y * 0.5], -1)\n","\n","    x = tf.image.crop_and_resize(x[None, :, :, :], boxes, box_indices, MODEL_INPUT_SIZE, method='bilinear')\n","\n","    # add some random noise for the robustness\n","    x += tf.random.normal(x.shape, stddev=noise_std, mean=0.0)\n","    x += tf.random.uniform(x.shape, minval=-noise_std/2.0, maxval=noise_std/2.0)\n","\n","    features = model(x, training=False)\n","    loss = tf.reduce_mean(tf.abs(features))\n","\n","  grads = tape.gradient(loss, [phase, image, magnitude_alpha])\n","  grads_phase, grads_image, grads_alpha = grads\n","\n","  return grads_phase, grads_image, grads_alpha, loss"],"metadata":{"id":"BBtQ-9bHaE-D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","import PIL\n","from PIL import Image\n","\n","sz = 2048\n","# sz = 512  # use a smaller image size as I don't have as much RAM...\n","\n","optimizer_class = Nadam\n","learning_rate = 1.0\n","initialization_std = 1.0\n","\n","nb_steps = 2048\n","\n","# Works for every model that are approximately in the range (-1, 1)\n","noise_std = 0.080\n","box_average_size = tf.cast(np.linspace(0.45, 0.30, nb_steps), tf.float32)\n","box_size_std = 0.05\n","\n","magnitude_template, phase = init_buffer(size=sz, std=initialization_std)\n","phase = tf.Variable(phase, trainable=True)\n","magnitude_alpha = tf.Variable(tf.zeros(magnitude_template.shape), trainable=True)\n","\n","optimizer = optimizer_class(learning_rate)\n","transparency = tf.zeros((magnitude_template.shape[1], magnitude_template.shape[1], 3))\n","for i in tqdm(range(nb_steps)):\n","\n","  grads, grads_img, grads_alpha, loss = up_neurons(model, magnitude_template, magnitude_alpha,\n","                                                            phase,\n","                                                            box_average_size=box_average_size[i],\n","                                                            box_size_std=box_size_std,\n","                                                            noise_std=noise_std,\n","                                                            nb_crops=8)\n","                                                            # nb_crops=32)\n","  optimizer.apply_gradients(zip([grads, grads_alpha], [phase, magnitude_alpha]))\n","\n","  transparency += tf.abs(grads_img)\n","\n","  if i == nb_steps-1 or (i+1) % 500 == 0: # if you want to plot every 25 steps\n","  #if i == nb_steps-1: # if you want to plot every 25 steps\n","    set_size(4, 4)\n","    img = fft_to_rgb(magnitude_template, magnitude_alpha, phase).numpy()\n","    viz = plot_alpha(img, transparency)\n","    plt.tight_layout()\n","    #plt.savefig(f'{logit_id}.png', dpi=350)\n","    #fn = f'flexiln_{vector_id}.npy'\n","    #np.save(fn, [img, transparency])\n","    #!cp {fn} \"/content/drive/MyDrive/  temp/ferroviaire\"\n","    plt.show()\n","    print(float(loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"17q3nig3Tir4HOBo8lWZuHomIpMrX8uJb"},"id":"I0aoh-y3aIFK","executionInfo":{"status":"ok","timestamp":1715361348945,"user_tz":-120,"elapsed":347917,"user":{"displayName":"Agustin Martin Picard","userId":"03361323072356609938"}},"outputId":"adf07e4e-ed69-4b0b-d6f2-dcd2aac5ab5e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["baseline = tf.image.resize(img, (240, 240))"],"metadata":{"id":"HD_bGtlVf-J3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["baseline_pred = model_vit(tf.expand_dims(baseline, axis=0))\n","top_k_classes = tf.argsort(baseline_pred, axis=-1, direction=\"DESCENDING\")[0,:5]\n","top_k_logit_values = tf.gather(tf.nn.softmax(baseline_pred[0]), top_k_classes)\n","print(f\"The top predicted classes are: {top_k_classes}\")\n","print(f\"The top predicted classes have softmax of: {top_k_logit_values}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLiCijRDgNlz","executionInfo":{"status":"ok","timestamp":1715362026333,"user_tz":-120,"elapsed":1564,"user":{"displayName":"Agustin Martin Picard","userId":"03361323072356609938"}},"outputId":"817beb2b-4032-4a77-bfb5-4a5c3f8975fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The top predicted classes are: [611 120  56  76 539]\n","The top predicted classes have softmax of: [0.00834914 0.00468772 0.0036605  0.00350103 0.00339187]\n"]}]},{"cell_type":"code","source":["# Compare to the zero baseline\n","baseline_pred = model_vit(tf.zeros((1, 240, 240, 3)))\n","top_k_classes = tf.argsort(baseline_pred, axis=-1, direction=\"DESCENDING\")[0,:5]\n","top_k_logit_values = tf.gather(tf.nn.softmax(baseline_pred[0]), top_k_classes)\n","print(f\"The top predicted classes are: {top_k_classes}\")\n","print(f\"The top predicted classes have softmax of: {top_k_logit_values}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"722bBe1li5aV","executionInfo":{"status":"ok","timestamp":1715362092618,"user_tz":-120,"elapsed":1117,"user":{"displayName":"Agustin Martin Picard","userId":"03361323072356609938"}},"outputId":"ee0c50eb-39d5-4ce3-9d9a-6c0c1632ad0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The top predicted classes are: [600 499 623 111 473]\n","The top predicted classes have softmax of: [0.00477141 0.00419894 0.00398186 0.0038865  0.00386721]\n"]}]},{"cell_type":"code","source":["# Compare to the uniform baseline\n","baseline_pred = model_vit(tf.random.uniform((1, 240, 240, 3)))\n","top_k_classes = tf.argsort(baseline_pred, axis=-1, direction=\"DESCENDING\")[0,:5]\n","top_k_logit_values = tf.gather(tf.nn.softmax(baseline_pred[0]), top_k_classes)\n","print(f\"The top predicted classes are: {top_k_classes}\")\n","print(f\"The top predicted classes have softmax of: {top_k_logit_values}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ub-uD7aOjHy8","executionInfo":{"status":"ok","timestamp":1715362127635,"user_tz":-120,"elapsed":642,"user":{"displayName":"Agustin Martin Picard","userId":"03361323072356609938"}},"outputId":"e9e34156-c7fe-4d27-8206-c3ad0ff6a623"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The top predicted classes are: [ 21  22  23 128 127]\n","The top predicted classes have softmax of: [0.10595558 0.06764202 0.05304189 0.04247993 0.03722423]\n"]}]},{"cell_type":"code","source":["# Energy of the baseline vs zero in model logits\n","energy_fv = tf.reduce_sum(tf.nn.sigmoid(model_vit(tf.expand_dims(baseline, axis=0))))\n","energy_zero = tf.reduce_sum(tf.nn.sigmoid(model_vit(tf.zeros((1, 240, 240, 3)))))\n","energy_uniform = tf.reduce_sum(tf.nn.sigmoid(model_vit(tf.random.uniform((1, 240, 240, 3)))))\n","print(f\"Energy of logits with fv = {energy_fv}\")\n","print(f\"Energy of logits with zero = {energy_zero}\")\n","print(f\"Energy of logits with uniform = {energy_uniform}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_2_-1HXjgFT","executionInfo":{"status":"ok","timestamp":1715362518780,"user_tz":-120,"elapsed":1067,"user":{"displayName":"Agustin Martin Picard","userId":"03361323072356609938"}},"outputId":"b89daca8-996c-4459-f7fd-8a5e73fab45a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Energy of logits with fv = 8.430586814880371\n","Energy of logits with zero = 8.160440444946289\n","Energy of logits with uniform = 15.198551177978516\n"]}]}]}